<!DOCTYPE html>
<html>
  <head>
  <meta charset=utf-8 />
  <title>  MCB111 Mathematics in Biology </title>
  <link rel="stylesheet" href="/Harvard-MCB111-2024-Fall/css/style.css" />
</head>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<body>
  <div id="main">
 
    <header>
      <h3> MCB111: Mathematics in Biology (Fall 2024) </h3>
    </header>
 
    <nav role="navigation"> 
      <a href="/Harvard-MCB111-2024-Fall">Home</a>  | <a href="/Harvard-MCB111-2024-Fall/schedule.html">Schedule</a> | <a href="https://canvas.harvard.edu/courses/139673/">Canvas</a> | <a href="https://piazza.com/harvard/fall2024/mcb111">Piazza</a> | <a href="/downloads/MCB111-syllabus.pdf">Syllabus [PDF]</a> | <a href="/downloads/StudentHours_2024.pdf">Student hours schedule [PDF]</a> <br/>
      
      Lectures:
      <a href="/Harvard-MCB111-2024-Fall/w00/w00-lecture.html"> w00 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w01/w01-lecture.html"> w01 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w02/w02-lecture.html"> w02 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w03/w03-lecture.html"> w03 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w04/w04-lecture.html"> w04 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w05/w05-lecture.html"> w05 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w06/w06-lecture.html"> w06 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w07/w07-lecture.html"> w07 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w08/w08-lecture.html"> w08 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w09/w09-lecture.html"> w09 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w10/w10-lecture.html"> w10 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w11/w11-lecture.html"> w11 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w12/w12-lecture.html"> w12 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w13/w13-lecture.html"> w13 </a> |
      <br/>
      
      inclass-notes:
      <a href="/Harvard-MCB111-2024-Fall/w02/w02-notes-lecture1.pdf"> w02-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w02/w02-notes-lecture2.pdf"> w02-l2 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w03/w03-notes-lecture1.pdf"> w03-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w04/w04-notes-l1.pdf"> w04-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w05/w05-notes-lectures.pdf"> w05 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w06/w06-notes-l1.pdf"> w06-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w06/w06-notes-l2.pdf"> w06-l2 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w07/w07-notes-l1.pdf"> w07-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w07/w07-notes-l2.pdf"> w07-l2 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w08/w08-notes-l1.pdf"> w08-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w08/w08-notes-l2.pdf"> w08-l2 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w09/w09-notes-l1.pdf"> w09-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w09/w09-notes-l2.pdf"> w09-l2 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w10/w10-notes-l1.pdf"> w10-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w10/w10-notes-l2.pdf"> w10-l2 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w10/w10-notes-l3.pdf"> w10-l3 </a> |
       <br/>
      
      inclass-code: 
      <a href="/Harvard-MCB111-2024-Fall/w00/w00-inclass.html"> w00 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w01/w01-sections_er_2024_complete.html"> w01 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w02/w02-lecture1.html"> w02-l1 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w02/w02-lecture2.html"> w02-l2 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w03/w03-lecture-code.ipynb"> w03 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w04/w04-lecture-code.ipynb"> w04 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w13/w13-code.ipynb"> w13 </a> |
      <br/>
      
      Sections: 
      <a href="/Harvard-MCB111-2024-Fall/w01/w01-sections.html"> w01 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w02/w02-sections.html"> w02 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w03/w03-sections_NH_2024.ipynb"> w03 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w04/w04-sections_2024.ipynb"> w04 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w05/w05-sections_2024.ipynb"> w05 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w08/w08-sections_2024.ipynb"> w08 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w09/w09-sections_2024-ER.ipynb"> w09 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w10/w10-sections_2024-NH.ipynb"> w10 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w11/w11-sections_2024_er.ipynb"> w11 </a> |
     <br/>
      
      
      Homeworks:
      <a href="/Harvard-MCB111-2024-Fall/w00/w00-homework.html"> w00 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w01/w01-homework.html"> w01 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w02/w02-homework.html"> w02 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w03/w03-homework.html"> w03 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w04/w04-homework.html"> w04 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w05/w05-homework.html"> w05 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w06/w06-homework.html"> w06 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w07/w07-homework.html"> w07 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w08/w08-homework.html"> w08 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w09/w09-homework.html"> w09 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w10/w10-homework.html"> w10 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w11/w11-homework.html"> w11 </a> |
      <a href="/Harvard-MCB111-2024-Fall/w13/w13-homework.html"> w13 </a> |
     <br/>
      
      Hints: 
      <a href="/Harvard-MCB111-2024-Fall/w00/w00-hints.html"> w00 </a> |
      <br/>
      

      Final:
      <br/>
 
     </nav>
    
    <br/>
 
    <ul id="markdown-toc">
  <li><a href="#preliminars" id="markdown-toc-preliminars">Preliminars</a></li>
  <li><a href="#q1" id="markdown-toc-q1">Q1</a></li>
  <li><a href="#choose-between-q2-or-q3" id="markdown-toc-choose-between-q2-or-q3">Choose between Q2 or Q3</a>    <ul>
      <li><a href="#q2" id="markdown-toc-q2">Q2</a></li>
      <li><a href="#q3" id="markdown-toc-q3">Q3</a></li>
    </ul>
  </li>
</ul>

<h1 class="no_toc" id="week-01">week 01:</h1>

<h1 class="no_toc" id="introduction-to-information-theory"><em>Introduction to Information Theory</em></h1>

<h2 id="preliminars">Preliminars</h2>

<p>Present all your reasoning, derivations, plots and code as part of the homework. Imagine that you are writing a short paper that anyone in class should to be able to understand.  If you are stuck in some point, please describe the issue and how far you got. A jupyter notebook if you are working in Python is not required, but recommended.</p>

<h2 id="q1">Q1</h2>

<p>In Sections, we derived the conditions that determine when we should
expect to find one single copy of a motif of length \(l\) in a genome
of length \(L\) when all four residues A, C, G, T are equally
likely. In general genomes have certain biases. The human genome
(\(3.1\times 10^{9}\) bases) has an average content of 42% G-C. Some
Archaea thermophiles can be really extreme in their base composition,
for instance malaria parasite <em>Plasmodium falciparum</em>, for example, has
a GC-content of 20% and a genome size of roughly \(10^7\).</p>

<ul>
  <li>
    <p>Derive an expression for the length \(l\) of a motif expected to
be unique in a genome of length \(L\) with arbitrary probabilities
\(p_A, p_C, p_G, p_T\).</p>
  </li>
  <li>
    <p>Particularize for the human genome and the P. falciparium genome.</p>
  </li>
  <li>
    <p>Sample a human-like genome and show how well your estimation
works. Select a particular motif of the estimated unique length,
and test experimentally how many times you actually find the motif
in your simulated genome.  Repeat the experiment to get a variance
of your estimate.</p>
  </li>
</ul>

<h2 id="choose-between-q2-or-q3">Choose between Q2 or Q3</h2>

<p>Q2 is a theoretical question, no coding is involved. You have the
option of answering Q2 or going straight to Q3. Extra credit if you
answer both.</p>

<h3 id="q2">Q2</h3>

<p>Consider a system of 3 neurons that are all interconnected. We are going to assume that
each neuron \(n_i\) has two states +1 for firing and -1 for not firing.</p>

<p>Your experimental design allows you only to measure two neurons
simultaneously (but not three at the time unfortunately), and what you
can obtain is the averages of those pair measurements</p>

\[\begin{aligned}
J_{12} = &lt; n_1 n_2 &gt;_{\mbox{obs}} \\
J_{13} = &lt; n_1 n_3 &gt;_{\mbox{obs}}\\
J_{23} = &lt; n_2 n_3 &gt;_{\mbox{obs}}\\
\end{aligned}\]

<p>Obviously, these averages are symmetric so we only need to consider
the three cases above, as \(&lt; n_1 n_2&gt;_{\mbox{obs}} =
&lt; n_2 n_1&gt;_{\mbox{obs}}\), etc..</p>

<ul>
  <li>Calculate the probability distribution that describes state of the three neurons,</li>
</ul>

<p>\begin{equation}
  P(n_1, n_2, n_3)
  \end{equation}</p>

<p>that has the maximum entropy if you <strong>impose</strong> the average
  correlations \(J_{12}, J_{13},J_{23}\) that you have observed.</p>

<p>Notice that the correlations are defined by</p>

\[\begin{aligned}
  &lt; n_1 n_2 &gt; = \sum_{n_1=1,-1}\sum_{n_2=1,-1}\sum_{n_3=1,-1} n_1 n_2\ P(n_1 n_2 n_3)\\
  &lt; n_1 n_3 &gt; = \sum_{n_1=1,-1}\sum_{n_2=1,-1}\sum_{n_3=1,-1} n_1 n_3\ P(n_1 n_2 n_3)\\
  &lt; n_2 n_3 &gt; = \sum_{n_1=1,-1}\sum_{n_2=1,-1}\sum_{n_3=1,-1} n_2 n_3\ P(n_1 n_2 n_3)\\
  \end{aligned}\]

<ul>
  <li>Can you generalize to \(n\) neurons for which you know all average pairwise measurements?</li>
</ul>

<p>If you need some inspiration, you may want to look into this paper
<a href="schneidman.pdf">Schneidman E, Still S, Berry MJ, Sergev R, Bialek W (2006) Weak
pairwise correlations imply strongly correlated network states in a
neural population</a>. In this manuscript, Schneidman <em>et
al.</em> show that in vertebrate retina, the maximum entropy model that
captures just pairwise correlations (like the one we have introduced
here) is sufficient to account for the majority of other non-pairwise
collective behaviors.</p>

<h3 id="q3">Q3</h3>

<p>For this question, we are going back to our experiment with
<em>P. falciparium</em> aggregation probability. In
<a href="../w00/w00-homework.html##Q2">Q2</a> of the previous homework, you were
requested to compare the probability distribution for the aggregation
probability from the bacteria in your current (low sample \(N=10\))
experiment on some new conditions, with that derived from a well
determined set of standard conditions.</p>

<p>You were asked to compare several samples of similar size in a
qualitative way as to whether you thought they could be from the same
distribution or not.</p>

<p>Now, with the material we learned in this
weekâ€™s lecture, you can address that question again doing a
quantitative comparison of the actual probability
distributions. Hopefully, your conclusions from last week will not
change (or if they do, explain), but you should be able to give
numbers for the corresponding comparisons.</p>

<ul>
  <li>
    <p>For instance, a good exercise would be to determine if the KL divergence
you observe from your <a href="../w00/data1.csv">data1</a> distribution to a
\(N=10\) subsample of <a href="../w00/data_default.csv">data_default</a> is
distinguishable from the same quantity but calculated between two
\(N=10\) samples of <a href="../w00/data_default.csv">data_default</a>.</p>
  </li>
  <li>
    <p>In fact, you can repeat the experiment several times and calculate
the PFD (or CDF) for two random variables: one of the random
variables measures the difference between data1 and \(N=10\)
samples of data_default, the other random variable measures the
difference between two \(N=10\) data_default samples.
You can calculate the difference by drawing the two distributions, and reporting their Kullback-Leibler divergence.</p>
  </li>
</ul>


 
    <footer>
      <hr>
      <p>
        <a href="http://rivaslab.org">Elena Rivas</a> | Harvard University
    </footer>
 
  </div>
</body>
</html>
